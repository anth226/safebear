{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import openai\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6f9d9a7",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53198300",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./bert-multilingual/toxic/jigsaw-unintended-bias-train_fr_clean.csv').sample(frac=1,random_state=42)\n",
    "\n",
    "# Ignore severe_toxic as they are very few and ve can use toxic confidence as severity.\n",
    "labels = ['toxic','obscene', 'threat', 'insult', 'identity_attack']\n",
    "for label in labels:\n",
    "    df[label] = (df[label] > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770b4afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat((\n",
    "  df[(df.toxic == 1) & (df.threat==0)].head(300), # almost all the threat examples contains toxic as second label, seperate them\n",
    "  df[df.threat==1].head(100),\n",
    "  df[((df.toxic == 0) & (df.severe_toxicity == 0) & (df.obscene == 1) & (df.threat == 0) & (df.insult == 0) & (df.identity_attack == 0))].head(100), # very few obscene in toxics, increase population\n",
    "  df[((df.toxic == 0) & (df.severe_toxicity == 0) & (df.obscene == 0) & (df.threat == 0) & (df.insult == 1) & (df.identity_attack == 0))].head(50), # add some insult without toxic\n",
    "  df[((df.toxic == 0) & (df.severe_toxicity == 0) & (df.obscene == 0) & (df.threat == 0) & (df.insult == 0) & (df.identity_attack == 1))].head(100), # add some identity_attack without toxic\n",
    "))\n",
    "\n",
    "# add complete neutral samples\n",
    "df1 = pd.concat((\n",
    "  df1,\n",
    "  df[((df.toxic == 0) & (df.severe_toxicity == 0) & (df.obscene == 0) & (df.threat == 0) & (df.insult == 0) & (df.identity_attack == 0))].head(1000-len(df1))\n",
    "))\n",
    "\n",
    "df1 = df1.rename(columns={'comment_text':'text'})\n",
    "df1 = df1[['text']+labels]\n",
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39beddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    print(label, df1[label].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b593c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('./jigsaw_test_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2239a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: delete\n",
    "df1 = pd.read_csv('prediction_results.csv')\n",
    "len(df1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d88ef0c1",
   "metadata": {},
   "source": [
    "# OpenAI Multi-Label Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7173a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2936c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(input_text, model=\"text-davinci-003\", retry=0):    \n",
    "    prompt = f\"\"\"The following is a list of text categories:\n",
    "    1. toxic\n",
    "    2. obscene\n",
    "    3. threat\n",
    "    4. insult\n",
    "    5. identity_attack\n",
    "    Classify the following French text as one or multiple of the above categories (Write numbers, no text):\n",
    "    \"{input_text}\"\n",
    "    \"\"\"\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=100,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "    label = response[\"choices\"][0].text.strip()    \n",
    "    return label\n",
    "\n",
    "def classify_text_binary(input_text, model=\"text-davinci-003\", retry=0):    \n",
    "    prompt = f\"\"\"Is the following French text is toxic? (just say yes/no):{input_text} \"\"\"\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=100,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "    label = response[\"choices\"][0].text.strip()    \n",
    "    return label.strip()\n",
    "\n",
    "def predict_with_retry(text,binary=False, retry=0):\n",
    "    try:\n",
    "        if binary:\n",
    "            return classify_text_binary(text)\n",
    "        else:\n",
    "            return classify_text(text)\n",
    "    except Exception as e:\n",
    "        if retry < 3:\n",
    "            print(\"Error, retrying in 3 sec\",e)\n",
    "            time.sleep(3)\n",
    "            return predict_with_retry(text, binary=binary, retry = retry+1)\n",
    "        else:\n",
    "            print(\"Reached max retry limit. Return None\")\n",
    "            return None          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed663e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i,row in tqdm(df1.iterrows(),total=len(df1)):    \n",
    "    prediction = predict_with_retry(row.text)\n",
    "    predictions.append(prediction)\n",
    "    time.sleep(1)\n",
    "    if len(predictions) % 40 == 0:\n",
    "        time.sleep(60)\n",
    "\n",
    "df1['pred_openai'] = predictions        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68d7d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i,row in tqdm(df1.iterrows(),total=len(df1)):    \n",
    "    prediction = predict_with_retry(row.text,binary=True)\n",
    "    predictions.append(prediction)\n",
    "    time.sleep(1)\n",
    "    if len(predictions) % 40 == 0:\n",
    "        time.sleep(60)\n",
    "\n",
    "df1['pred_openai_binary'] = predictions        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d45f1b7",
   "metadata": {},
   "source": [
    "# Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0424f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.environ.get(\"HIVE_API_KEY\")\n",
    "\n",
    "def classify_text(input_text):\n",
    "    response = requests.post(\n",
    "        url='https://api.thehive.ai/api/v2/task/sync',\n",
    "        headers={'Authorization': f'Token {API_KEY}'},\n",
    "        data={'text_data': input_text},\n",
    "    )\n",
    "    response_dict = response.json()\n",
    "    \n",
    "    res = response_dict['status'][0]\n",
    "    return res['response']['output'][0]['classes']\n",
    "\n",
    "def predict_with_retry(text,retry=0):\n",
    "    try:\n",
    "        return classify_text(text)\n",
    "    except Exception as e:\n",
    "        if retry < 3:\n",
    "            print(\"Error, retrying in 3 sec\",e)\n",
    "            time.sleep(3)\n",
    "            return predict_with_retry(text, retry = retry+1)\n",
    "        else:\n",
    "            print(\"Reached max retry limit. Return None\")\n",
    "            return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a156a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i,row in tqdm(df1.iterrows(),total=len(df1)):    \n",
    "    prediction = predict_with_retry(row.text)\n",
    "    predictions.append(prediction)\n",
    "    time.sleep(3)\n",
    "\n",
    "    if len(predictions) % 40 == 0:\n",
    "        time.sleep(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72108141",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['pred_hive'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d95fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('./prediction_results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "761dcc2e730670a5406af1e4d952870e7bed611eb3687403cb5a8f4459e63789"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
